{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51294875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import torch.nn\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b51546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66a4ac69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "ones: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# zeros\n",
    "X = torch.zeros(2,3)\n",
    "print(\"zeros:\", X)\n",
    "X = torch.ones(2,3)\n",
    "print('ones:',X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc47ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the shape\n",
    "X.view(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d752cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## move tensor to data cpu or arracy\n",
    "X.data.cpu()\n",
    "X.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c6cf3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0.2566])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25659292936325073"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(1)\n",
    "print(\"X:\",X)\n",
    "X.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e28c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten tensor\n",
    "# torch.flatten(X,start_dim=0)\n",
    "torch.flatten(X,start_dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5877de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tensor size\n",
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "190bee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data loader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import h5py\n",
    "rotation =10\n",
    "\n",
    "def _load_data(DATA_PATH, batch_size):\n",
    "    '''Data loader'''\n",
    "    print(\"data_path: \", DATA_PATH)\n",
    "    train_trans = transforms.Compose([transforms.RandomRotation(rotation),transforms.RandomHorizontalFlip(),\\\n",
    "                                      transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
    "    \n",
    "    train_dataset = torchvision.datasets.MNIST(root=DATA_PATH, download=True,train=True, transform=train_trans)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,num_workers=8)\n",
    "    ## for testing\n",
    "    test_trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
    "    test_dataset = torchvision.datasets.MNIST(root=DATA_PATH, download=True, train=False, transform=test_trans)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1c7012b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path:  ./data/\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817af3f009c7498b9ef7782c4f49d22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172ce06c822a4f9884f3cbddcfa40c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48a89182c6442bc820c1c2a511ce181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54820d7faf8049adb1985e07260d3051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huajieshao/opt/anaconda3/envs/torch-env/lib/python3.9/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 5, 0, 0, 1, 2, 0, 6, 6, 2, 3, 1, 5, 8, 4, 0, 5, 3, 5, 3, 6, 9, 6, 3,\n",
      "        8, 6, 3, 0, 3, 4, 6, 6, 1, 4, 9, 5, 7, 5, 5, 0, 3, 6, 9, 3, 3, 8, 2, 0,\n",
      "        2, 8, 3, 6, 0, 1, 1, 2, 4, 2, 6, 7, 9, 8, 6, 3, 3, 3, 9, 9, 6, 0, 2, 7,\n",
      "        9, 7, 8, 7, 2, 8, 6, 0, 9, 2, 9, 2, 7, 1, 4, 3, 0, 5, 7, 8, 4, 8, 1, 9,\n",
      "        9, 0, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"./data/\"\n",
    "batch_size = 100\n",
    "train_loader, test_loader = _load_data(DATA_PATH, batch_size)\n",
    "for data,label in train_loader:\n",
    "    print(label)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2de19954",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 1\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.FC1 = nn.Linear(28,30) ## fully connected layer\n",
    "        act = nn.ReLU()  ## activation fun\n",
    "        drop = nn.Dropout(p=0.2)  ## dropout\n",
    "        self.FC2 = nn.Linear(30,10) ## fully connected layer\n",
    "#         act = nn.ReLU()  ## activation fun\n",
    "    ## feed data to the model\n",
    "    def forward(self,x):\n",
    "        h = self.FC1(x)\n",
    "        h = act(h)\n",
    "        h = drop(h)\n",
    "        y_out = self.FC2(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bafa88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method 2\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(nn.Linear(28*28,50),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(50,20),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(20,10))\n",
    "    ## feed data into the model\n",
    "    def forward(self,x):\n",
    "        y_out = self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d38a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tensorboard\n",
    "writer = SummaryWriter()\n",
    "loss1 = 10\n",
    "n_iter1 = 1\n",
    "\n",
    "loss2 = 5\n",
    "n_iter2 = 2\n",
    "\n",
    "# loss3 = 1\n",
    "# n_iter3 = 3\n",
    "\n",
    "writer.add_scalar('Loss/train', loss1, n_iter1)\n",
    "writer.add_scalar('Loss/train', loss2, n_iter2)\n",
    "# writer.add_scalar('Loss/train', loss3, n_iter3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98b7f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the training curve locally\n",
    "# http://localhost:6006/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
